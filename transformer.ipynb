{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9429704a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFViTForImageClassification, ViTFeatureExtractor\n",
    "from utils import *\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3949e453",
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(physical_devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad71f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (512,384)\n",
    "early_stopping = EarlyStopping(monitor='accuracy', patience=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c2f812",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_vit_pretrained(size: tuple[int, int], fine_tune: bool = False, model_name: str = 'google/vit-small-patch16-224'):\n",
    "    \"\"\"\n",
    "    Creates an image classification model using a pre-trained Vision Transformer (ViT).\n",
    "\n",
    "    Args:\n",
    "        size (tuple[int, int]): Target input image size (height, width).\n",
    "                                Note: ViT models often expect specific input sizes (e.g., 224x224).\n",
    "                                The feature extractor will handle resizing. The default model\n",
    "                                'google/vit-small-patch16-224' expects 224x224 inputs.\n",
    "        fine_tune (bool): If True, unfreezes the weights of the pre-trained\n",
    "                          ViT base model for fine-tuning. Defaults to False.\n",
    "        model_name (str): The name of the pre-trained ViT model to load from\n",
    "                          Hugging Face Hub. Defaults to 'google/vit-small-patch16-224'.\n",
    "                          Other options include 'google/vit-base-patch16-224-in21k', etc.\n",
    "\n",
    "    Returns:\n",
    "        tf.keras.Model: A Keras model ready for compilation and training.\n",
    "        ViTFeatureExtractor: The feature extractor for preprocessing images.\n",
    "    \"\"\"\n",
    "    num_classes = 6 # Number of trash classes\n",
    "\n",
    "    # Load the pre-trained ViT model for image classification.\n",
    "    # We specify the number of labels and explicitly ignore the mismatch\n",
    "    # in the classification head dimensions, as we intend to train it.\n",
    "    print(f\"Loading pre-trained model: {model_name}\")\n",
    "    model = TFViTForImageClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=num_classes,\n",
    "        ignore_mismatched_sizes=True # Allows loading a new classification head\n",
    "    )\n",
    "\n",
    "    # Load the feature extractor associated with the model.\n",
    "    # This handles resizing, normalization, etc.\n",
    "    feature_extractor = ViTFeatureExtractor.from_pretrained(model_name)\n",
    "\n",
    "    # --- Freezing/Unfreezing Layers ---\n",
    "    # Access the base ViT model within the classification model\n",
    "    base_model = model.vit\n",
    "\n",
    "    if not fine_tune:\n",
    "        # Freeze all layers in the base ViT model\n",
    "        print(\"Freezing base ViT model weights.\")\n",
    "        base_model.trainable = False\n",
    "    else:\n",
    "        # Unfreeze all layers in the base ViT model for fine-tuning\n",
    "        print(\"Unfreezing base ViT model weights for fine-tuning.\")\n",
    "        base_model.trainable = True\n",
    "        # Note: Unlike the ResNet example, fine-tuning transformers often involves\n",
    "        # unfreezing the entire base or specific blocks rather than just the last N layers.\n",
    "        # Unfreezing the whole base is a common strategy.\n",
    "\n",
    "    # The classification head added by TFViTForImageClassification is automatically trainable.\n",
    "\n",
    "    # --- Model Definition (Implicit) ---\n",
    "    # The `TFViTForImageClassification` class already combines the base ViT\n",
    "    # and the classification head into a single Keras model.\n",
    "\n",
    "    print(f\"Model '{model_name}' loaded.\")\n",
    "    # The feature extractor knows the required input size\n",
    "    print(f\"Input size expected by feature extractor: {feature_extractor.size}\")\n",
    "    print(f\"Number of output classes: {num_classes}\")\n",
    "    print(f\"Base model trainable: {base_model.trainable}\")\n",
    "\n",
    "    # Note: The model is returned uncompiled. Compilation should happen before training.\n",
    "    return model, feature_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ece8669",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
